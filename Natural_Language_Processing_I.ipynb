{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8d770e96-327c-478d-b610-a2a07f0f84d8",
      "metadata": {
        "id": "8d770e96-327c-478d-b610-a2a07f0f84d8"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0a8a6ed-3b5f-4125-a79e-e4f9b6652677",
      "metadata": {
        "id": "e0a8a6ed-3b5f-4125-a79e-e4f9b6652677"
      },
      "outputs": [],
      "source": [
        "text = \"     \\t\\t <b>Natural   language  processing (NLP)<b>    is a branch of   artificial intelligence (AI)   that enables computers to comprehend, generate, and manipulate human language.\\n Natural language  processing has the ability to    interrogate the   data with natural   language text or voice.                 \\n Check out this article for more information: https://en.wikipedia.org/wiki/Natural_language_processing.\\n Natural language processing has its roots in the 1940s. Already in 1940, Alan Turing published an article titled Computing Machinery and Intelligence which proposed what is now called the Turing test as a criterion of intelligence,\"\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edc51d3a-9fde-419e-85cf-e82dfaaa4f44",
      "metadata": {
        "id": "edc51d3a-9fde-419e-85cf-e82dfaaa4f44"
      },
      "source": [
        "**Whitespace Removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a378b124-1ec5-470d-9156-3a381fc57f9f",
      "metadata": {
        "id": "a378b124-1ec5-470d-9156-3a381fc57f9f"
      },
      "outputs": [],
      "source": [
        "# remove leading and trailing white space\n",
        "\n",
        "text = text.strip()\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1a131eb-efe5-45a8-886d-2920288abd35",
      "metadata": {
        "id": "c1a131eb-efe5-45a8-886d-2920288abd35"
      },
      "outputs": [],
      "source": [
        "# replace multiple consecutive white space characters with a single space\n",
        "\n",
        "text = \" \".join(text.split())\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c497be2e-a498-4e39-bd72-650a44babef3",
      "metadata": {
        "id": "c497be2e-a498-4e39-bd72-650a44babef3"
      },
      "source": [
        "**URL and HTML Removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aec1176-9027-4f9c-b5f2-75405be522b1",
      "metadata": {
        "id": "3aec1176-9027-4f9c-b5f2-75405be522b1"
      },
      "outputs": [],
      "source": [
        "# regular expression pattern to match URLs\n",
        "url_pattern = r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\"\n",
        "\n",
        "# replace URLs with an empty string\n",
        "text = re.sub(url_pattern, \"\", text)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "745c0b8c-6c03-4d82-93bb-ff1e763fb415",
      "metadata": {
        "id": "745c0b8c-6c03-4d82-93bb-ff1e763fb415"
      },
      "source": [
        "**HTML Code Removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e13277d2-6714-4690-82a7-2347a5546796",
      "metadata": {
        "id": "e13277d2-6714-4690-82a7-2347a5546796"
      },
      "outputs": [],
      "source": [
        "# rgular expression pattern to match HTML tags\n",
        "html_pattern = r\"<[^>]+>\"\n",
        "\n",
        "# replace HTML tags with an empty string\n",
        "text = re.sub(html_pattern, \"\", text)\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af46f2d4-7786-4315-8091-54f643c5f84c",
      "metadata": {
        "id": "af46f2d4-7786-4315-8091-54f643c5f84c"
      },
      "source": [
        "**Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "571c1680-4d6a-4ff9-8a1c-0a5d901cb8f3",
      "metadata": {
        "id": "571c1680-4d6a-4ff9-8a1c-0a5d901cb8f3"
      },
      "outputs": [],
      "source": [
        "# Split sentence into words and punctuations\n",
        "# requires punkt package - nltk.download('punkt')\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbd69814-4729-4148-9a4f-a7dadd9520f4",
      "metadata": {
        "id": "bbd69814-4729-4148-9a4f-a7dadd9520f4"
      },
      "outputs": [],
      "source": [
        "# Sentence tokenizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "print(sent_tokenize(text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80618720-2bd7-48b1-8edd-6267d3dfd9dd",
      "metadata": {
        "id": "80618720-2bd7-48b1-8edd-6267d3dfd9dd"
      },
      "source": [
        "**Part-of-Speech Tagging**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81864d18-e083-4e36-b0ed-84ecd4ffd66a",
      "metadata": {
        "id": "81864d18-e083-4e36-b0ed-84ecd4ffd66a"
      },
      "outputs": [],
      "source": [
        "from nltk import pos_tag\n",
        "\n",
        "tagged_tokens = pos_tag(tokens)\n",
        "print(tagged_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1d7f073-a3be-4b3a-b706-fa0eaa80f153",
      "metadata": {
        "id": "b1d7f073-a3be-4b3a-b706-fa0eaa80f153"
      },
      "source": [
        "**Named-Entity Recognition**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d53418bf-884f-407f-84c3-a1e6587ee05a",
      "metadata": {
        "id": "d53418bf-884f-407f-84c3-a1e6587ee05a"
      },
      "outputs": [],
      "source": [
        "from nltk import ne_chunk\n",
        "\n",
        "ne_chunk(tagged_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf9e7c68-ccd1-465f-b448-19da7cc088a5",
      "metadata": {
        "id": "cf9e7c68-ccd1-465f-b448-19da7cc088a5"
      },
      "source": [
        "**Lowercasing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "775e21e4-f603-4219-bd56-feda0f1ee480",
      "metadata": {
        "id": "775e21e4-f603-4219-bd56-feda0f1ee480"
      },
      "outputs": [],
      "source": [
        "tokens = [token.lower() for token in tokens]\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "550ffe0a-672f-4cca-bcaf-bcdbb8c340a4",
      "metadata": {
        "id": "550ffe0a-672f-4cca-bcaf-bcdbb8c340a4"
      },
      "outputs": [],
      "source": [
        "# equivalent for loop\n",
        "\n",
        "lowercased_tokens = []\n",
        "for token in tokens:\n",
        "    lowercased_tokens.append(token.lower())\n",
        "print(lowercased_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41e01045-fdb6-4928-9b2d-e57265f7cb73",
      "metadata": {
        "id": "41e01045-fdb6-4928-9b2d-e57265f7cb73"
      },
      "source": [
        "**Punctuation Removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52d780dc-566a-4792-9141-fe82377976e5",
      "metadata": {
        "id": "52d780dc-566a-4792-9141-fe82377976e5"
      },
      "outputs": [],
      "source": [
        "# punctuations\n",
        "\n",
        "print(string.punctuation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20a98e99-ce4f-48b6-93c4-69838612c8e2",
      "metadata": {
        "id": "20a98e99-ce4f-48b6-93c4-69838612c8e2"
      },
      "outputs": [],
      "source": [
        "# exclude punctuations\n",
        "\n",
        "tokens = [token for token in tokens if token not in string.punctuation]\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2d0e71d-c232-43c8-9e83-6a747bb1ae63",
      "metadata": {
        "id": "f2d0e71d-c232-43c8-9e83-6a747bb1ae63"
      },
      "outputs": [],
      "source": [
        "# equivalent for loop\n",
        "\n",
        "punctuation_free_tokens = []\n",
        "for token in tokens:\n",
        "    if token not in string.punctuation:\n",
        "        punctuation_free_tokens.append(token)\n",
        "print(punctuation_free_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "017a83a9-9161-40c7-9bf4-523afc5e959e",
      "metadata": {
        "id": "017a83a9-9161-40c7-9bf4-523afc5e959e"
      },
      "source": [
        "**Stemming**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f1e14b-146c-41cd-b2c2-6ee63e40ebba",
      "metadata": {
        "id": "d0f1e14b-146c-41cd-b2c2-6ee63e40ebba"
      },
      "outputs": [],
      "source": [
        "# removes common suffixes from words to get close to base form\n",
        "# e.g. sized -> size, flies -> fli,\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "print(stemmer.stem('sized'))\n",
        "print(stemmer.stem('sizing'))\n",
        "print(stemmer.stem('flies'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10d28df-87ff-4adc-bf94-9219e489e0ac",
      "metadata": {
        "id": "d10d28df-87ff-4adc-bf94-9219e489e0ac"
      },
      "outputs": [],
      "source": [
        "# apply stemming on each word\n",
        "\n",
        "stemmed_tokens = [stemmer.stem(token) for token in tokens]\n",
        "print(stemmed_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27258e0b-6184-4aea-bc45-cce0160445de",
      "metadata": {
        "id": "27258e0b-6184-4aea-bc45-cce0160445de"
      },
      "source": [
        "**Lemmatization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "daa2ace1-6b3e-4c2b-9a2b-26ba376e3240",
      "metadata": {
        "id": "daa2ace1-6b3e-4c2b-9a2b-26ba376e3240"
      },
      "outputs": [],
      "source": [
        "# transforming words to base form\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "print(lemmatizer.lemmatize('sized'))\n",
        "print(lemmatizer.lemmatize('flies'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac4916ff-cf26-4685-acce-b17c0ea59a6a",
      "metadata": {
        "scrolled": true,
        "id": "ac4916ff-cf26-4685-acce-b17c0ea59a6a"
      },
      "outputs": [],
      "source": [
        "# apply lemmatization on each word\n",
        "\n",
        "tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f5a164b-c3de-421b-82f0-77242a20df05",
      "metadata": {
        "id": "9f5a164b-c3de-421b-82f0-77242a20df05"
      },
      "source": [
        "**Stopword Removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d188711f-c158-4a36-b0b4-39055d5ff376",
      "metadata": {
        "id": "d188711f-c158-4a36-b0b4-39055d5ff376"
      },
      "outputs": [],
      "source": [
        "# stopwords\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords_list = stopwords.words(\"english\")\n",
        "print(stopwords_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d92616ac-c606-4e21-8198-61450b86e141",
      "metadata": {
        "id": "d92616ac-c606-4e21-8198-61450b86e141"
      },
      "outputs": [],
      "source": [
        "# languages available\n",
        "\n",
        "print(stopwords.fileids())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5b032788-8a48-41c4-bbae-7040fc90f3f9",
      "metadata": {
        "id": "5b032788-8a48-41c4-bbae-7040fc90f3f9"
      },
      "outputs": [],
      "source": [
        "# exclude stopwords - need .lower() becuase stopwords are in lower case\n",
        "\n",
        "tokens = [token for token in tokens if token.lower() not in stopwords_list]\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5f5f7bfd-7121-43aa-a61e-cbb0927c83a1",
      "metadata": {
        "id": "5f5f7bfd-7121-43aa-a61e-cbb0927c83a1"
      },
      "outputs": [],
      "source": [
        "# equivalent for loop\n",
        "\n",
        "stopword_free_tokens = []\n",
        "for token in tokens:\n",
        "    if token.lower() not in stopwords_list:\n",
        "        stopword_free_tokens.append(token)\n",
        "print(stopword_free_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48021716-12ca-4c2d-8231-309bb6ec2ff4",
      "metadata": {
        "id": "48021716-12ca-4c2d-8231-309bb6ec2ff4"
      },
      "source": [
        "**Frequent Word Removal**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f358a59-f10c-4f89-9bf3-48e70d3a1ec7",
      "metadata": {
        "id": "6f358a59-f10c-4f89-9bf3-48e70d3a1ec7"
      },
      "outputs": [],
      "source": [
        "# word frequency distribution\n",
        "\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "fdist = FreqDist(tokens)\n",
        "fdist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49e95654-07c0-4fdd-b5ff-126b4cad7285",
      "metadata": {
        "id": "49e95654-07c0-4fdd-b5ff-126b4cad7285"
      },
      "outputs": [],
      "source": [
        "# count of each word\n",
        "\n",
        "fdist['natural']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee386acb-bfa4-48c7-82e1-660ec7e1c703",
      "metadata": {
        "id": "ee386acb-bfa4-48c7-82e1-660ec7e1c703"
      },
      "outputs": [],
      "source": [
        "# total word count\n",
        "\n",
        "fdist.N() * 0.15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1742ac68-bc39-4155-8591-1863c842cdb8",
      "metadata": {
        "id": "1742ac68-bc39-4155-8591-1863c842cdb8"
      },
      "outputs": [],
      "source": [
        "# exclude words that constitute 15% of total word frequency\n",
        "\n",
        "tokens = [token for token in tokens if  fdist[token] < 0.15*fdist.N()]\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b37e897-be30-4432-97ba-1f93f373ec8a",
      "metadata": {
        "id": "9b37e897-be30-4432-97ba-1f93f373ec8a"
      },
      "source": [
        "**Spelling Correction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "da518e3e-1ad5-4a32-8bb6-cabd9f4e7190",
      "metadata": {
        "id": "da518e3e-1ad5-4a32-8bb6-cabd9f4e7190"
      },
      "outputs": [],
      "source": [
        "# language vocabulary\n",
        "\n",
        "from nltk.corpus import words\n",
        "\n",
        "vocabulary = words.words()\n",
        "print(len(vocabulary))\n",
        "print(vocabulary[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b59afb1-728d-4159-a793-0ae0dfa95217",
      "metadata": {
        "id": "6b59afb1-728d-4159-a793-0ae0dfa95217"
      },
      "outputs": [],
      "source": [
        "# edit-distance: number of changes required to transform one word into another\n",
        "\n",
        "from nltk.metrics import edit_distance\n",
        "\n",
        "print(edit_distance('hello', 'helo'))\n",
        "print(edit_distance('hello', 'helloo'))\n",
        "print(edit_distance('hello', 'bye'))\n",
        "print(edit_distance('hello', 'hello'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e917eec-7dfe-4eae-adaa-fcf55e056a06",
      "metadata": {
        "id": "6e917eec-7dfe-4eae-adaa-fcf55e056a06"
      },
      "outputs": [],
      "source": [
        "# correct spelling of each word\n",
        "\n",
        "corrected_tokens = []\n",
        "for token in tokens:\n",
        "    # calculate edit distance of each token with all words in vocabulary\n",
        "    # to find the word with the lowest edit distance\n",
        "    # correctly spelled words will have distance 0 with themselved\n",
        "    distances = np.array([edit_distance(x, token) for x in vocabulary])\n",
        "    corrected_token = vocabulary[np.argmin(distances)]\n",
        "    corrected_tokens.append(corrected_token)\n",
        "print(corrected_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3c9aa6c-4ae7-42a9-b346-8ce199adbbfa",
      "metadata": {
        "id": "a3c9aa6c-4ae7-42a9-b346-8ce199adbbfa"
      },
      "source": [
        "**Exercise 10.1** Write a language detector that uses stopwords to identify the language used in a given text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7be339f6-f043-4a55-b29c-a271ca38dc3d",
      "metadata": {
        "id": "7be339f6-f043-4a55-b29c-a271ca38dc3d"
      },
      "outputs": [],
      "source": [
        "def detect_language(text):\n",
        "    # TODO: Your Code Here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6b3d38c-aca4-41d7-b372-c39befff7e54",
      "metadata": {
        "id": "e6b3d38c-aca4-41d7-b372-c39befff7e54"
      },
      "source": [
        "**Text Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79f25498-7dfe-4c4d-ab9a-ad1dc5d7d088",
      "metadata": {
        "id": "79f25498-7dfe-4c4d-ab9a-ad1dc5d7d088"
      },
      "outputs": [],
      "source": [
        "# file reading\n",
        "\n",
        "with open('sherlock.txt', 'r') as f:\n",
        "    raw_text = f.read()\n",
        "raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c6f319-858d-4220-8e3e-5f9afc0f66ef",
      "metadata": {
        "id": "36c6f319-858d-4220-8e3e-5f9afc0f66ef"
      },
      "outputs": [],
      "source": [
        "# tokenize\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(raw_text)\n",
        "print(tokens[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "940435e4-e747-4d58-8d3c-c9494a0ae979",
      "metadata": {
        "id": "940435e4-e747-4d58-8d3c-c9494a0ae979"
      },
      "outputs": [],
      "source": [
        "# lowercase\n",
        "\n",
        "tokens = [token.lower() for token in tokens]\n",
        "print(tokens[:50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe2c4dba-76ea-4eda-8e69-cb291d0f9ab0",
      "metadata": {
        "id": "fe2c4dba-76ea-4eda-8e69-cb291d0f9ab0"
      },
      "outputs": [],
      "source": [
        "# Text class\n",
        "\n",
        "from nltk.text import Text\n",
        "\n",
        "text = Text(tokens)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c1989f5-1a15-432c-b18c-a9ad5326f374",
      "metadata": {
        "id": "3c1989f5-1a15-432c-b18c-a9ad5326f374"
      },
      "outputs": [],
      "source": [
        "# frequency distribution of words\n",
        "\n",
        "text.vocab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d10c50bf-59ca-4950-9537-2a66aa14a6ca",
      "metadata": {
        "id": "d10c50bf-59ca-4950-9537-2a66aa14a6ca"
      },
      "outputs": [],
      "source": [
        "# word frequency\n",
        "\n",
        "text.count('sherlock')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63e9ad43-8edc-490e-9686-12f97e77b290",
      "metadata": {
        "id": "63e9ad43-8edc-490e-9686-12f97e77b290"
      },
      "outputs": [],
      "source": [
        "# first occurance of word\n",
        "\n",
        "text.index('sherlock')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6bb824db-c2a4-4f76-a87d-649dfe798415",
      "metadata": {
        "id": "6bb824db-c2a4-4f76-a87d-649dfe798415"
      },
      "outputs": [],
      "source": [
        "# display all occucrencecs of a word with context\n",
        "\n",
        "text.concordance(\"sherlock\", lines=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0357eb24-d9e5-494c-a4f3-ced9fcf3c585",
      "metadata": {
        "id": "0357eb24-d9e5-494c-a4f3-ced9fcf3c585"
      },
      "outputs": [],
      "source": [
        "# return list of word occurances with context\n",
        "\n",
        "concordances = text.concordance_list(\"sherlock\")\n",
        "concordances[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8ec00385-a027-4404-b2ad-b271df54257e",
      "metadata": {
        "id": "8ec00385-a027-4404-b2ad-b271df54257e"
      },
      "outputs": [],
      "source": [
        "# display words that occur together frequently\n",
        "\n",
        "text.collocations()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e995d834-dd37-438b-a825-997611d22257",
      "metadata": {
        "id": "e995d834-dd37-438b-a825-997611d22257"
      },
      "outputs": [],
      "source": [
        "# returns list of collocating words\n",
        "\n",
        "collocations = text.collocation_list()\n",
        "print(collocations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e75da5b0-fd94-43b1-b764-c2acecc499d9",
      "metadata": {
        "id": "e75da5b0-fd94-43b1-b764-c2acecc499d9"
      },
      "outputs": [],
      "source": [
        "# words that occur in the same context as specified word\n",
        "\n",
        "text.similar('holmes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51274b0e-9759-4472-901b-b46348323f93",
      "metadata": {
        "id": "51274b0e-9759-4472-901b-b46348323f93"
      },
      "outputs": [],
      "source": [
        "# contexts where word occurs frequently\n",
        "\n",
        "text.common_contexts(['holmes'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed3341fe-7aa8-4508-bc6b-1c2aa5edf8a6",
      "metadata": {
        "id": "ed3341fe-7aa8-4508-bc6b-1c2aa5edf8a6"
      },
      "outputs": [],
      "source": [
        "# plot most common words\n",
        "\n",
        "text.plot(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dcd408ca-05c3-4935-80df-c6f2796bb359",
      "metadata": {
        "id": "dcd408ca-05c3-4935-80df-c6f2796bb359"
      },
      "outputs": [],
      "source": [
        "# plot of where in text the specified words occur\n",
        "\n",
        "text.dispersion_plot(['sherlock', 'holmes', 'watson', 'lestrade'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4acd54f2-553e-4840-b42c-0c5404fc312d",
      "metadata": {
        "id": "4acd54f2-553e-4840-b42c-0c5404fc312d"
      },
      "source": [
        "**Corpus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f86622b-25d5-4dab-9fe0-fe14b04d5c8e",
      "metadata": {
        "id": "3f86622b-25d5-4dab-9fe0-fe14b04d5c8e"
      },
      "outputs": [],
      "source": [
        "# Gutenberg Corpus\n",
        "\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "print(gutenberg.fileids())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f45adf07-7203-4b84-adbf-7a4d4eb6be9f",
      "metadata": {
        "id": "f45adf07-7203-4b84-adbf-7a4d4eb6be9f"
      },
      "outputs": [],
      "source": [
        "# Alice in Wonderland\n",
        "\n",
        "alice = gutenberg.words('carroll-alice.txt')\n",
        "alice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e445ae-90a2-416e-9b8a-95e09e2e5b2e",
      "metadata": {
        "id": "38e445ae-90a2-416e-9b8a-95e09e2e5b2e"
      },
      "outputs": [],
      "source": [
        "text = Text(alice)\n",
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41bd7b0a-71f7-4011-b6a1-ae75d5d7e2e5",
      "metadata": {
        "id": "41bd7b0a-71f7-4011-b6a1-ae75d5d7e2e5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}